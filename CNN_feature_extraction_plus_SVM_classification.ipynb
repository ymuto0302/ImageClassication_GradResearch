{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37363216",
   "metadata": {},
   "source": [
    "# CNN による特徴抽出 + SVM による分類\n",
    "流れは以下のとおり：\n",
    "1. 最終層にて softmax + negative log likelihood loss にて評価しつつ，CNN を走らせる。\n",
    "1. 学習済みのCNNモデルを保存する。\n",
    "1. CNNモデルを読み込み，学習データを与えて特徴量を求める。\n",
    "1. Grid Search を用いて，SVC のパラメータ最適化を行う。\n",
    "1. 最適化されたパラメータ値を用いてテストデータを分類する。\n",
    "\n",
    "(メモ) 本ノートブックでケアできていない点は以下のとおり：\n",
    "- CNN モデルの最適化（例えば early stopping により損失最小のCNNモデルを保存する）\n",
    "- SVM のパラメータ集合のサイズが小さい"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bfecc",
   "metadata": {},
   "source": [
    "---\n",
    "## MNIST を対象として適当な CNN を走らせる\n",
    "以下のコードは，次のサイトからパクったものである。  \n",
    "https://qiita.com/takawamoto/items/42ff569be496621fc016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c90123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ネットワーク構造の定義\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,3,1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12*12*64,128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = f.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = f.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(-1,12*12*64)\n",
    "        x = self.fc1(x)\n",
    "        x = f.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x, f.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029a8d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "MyNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Train start\n",
      "Training: 1 epoch. 100 iteration. Loss: 0.9860961437225342\n",
      "Training: 1 epoch. 200 iteration. Loss: 1.3245478868484497\n",
      "Training: 1 epoch. 300 iteration. Loss: 1.4507863521575928\n",
      "Training: 1 epoch. 400 iteration. Loss: 1.5782066583633423\n",
      "Training: 1 epoch. 500 iteration. Loss: 1.3204110860824585\n",
      "Training: 1 epoch. 600 iteration. Loss: 1.5830055475234985\n",
      "Training: 1 epoch. 700 iteration. Loss: 1.0446257591247559\n",
      "Training: 1 epoch. 800 iteration. Loss: 1.2005428075790405\n",
      "Training: 1 epoch. 900 iteration. Loss: 1.0245047807693481\n",
      "Training: 1 epoch. 1000 iteration. Loss: 1.379652976989746\n",
      "Training: 1 epoch. 1100 iteration. Loss: 1.4718736410140991\n",
      "Training: 1 epoch. 1200 iteration. Loss: 1.1800692081451416\n",
      "Training: 1 epoch. 1300 iteration. Loss: 0.8880630135536194\n",
      "Training: 1 epoch. 1400 iteration. Loss: 1.463800311088562\n",
      "Training: 1 epoch. 1500 iteration. Loss: 1.1677629947662354\n",
      "Training: 1 epoch. 1600 iteration. Loss: 1.1952873468399048\n",
      "Training: 1 epoch. 1700 iteration. Loss: 1.2902498245239258\n",
      "Training: 1 epoch. 1800 iteration. Loss: 1.7590687274932861\n",
      "Training: 1 epoch. 1900 iteration. Loss: 1.003514051437378\n",
      "Training: 1 epoch. 2000 iteration. Loss: 1.4346346855163574\n",
      "Training: 1 epoch. 2100 iteration. Loss: 1.4480020999908447\n",
      "Training: 1 epoch. 2200 iteration. Loss: 1.4475412368774414\n",
      "Training: 1 epoch. 2300 iteration. Loss: 1.4357305765151978\n",
      "Training: 1 epoch. 2400 iteration. Loss: 1.6025742292404175\n",
      "Training: 1 epoch. 2500 iteration. Loss: 1.429082989692688\n",
      "Training: 1 epoch. 2600 iteration. Loss: 0.7121164202690125\n",
      "Training: 1 epoch. 2700 iteration. Loss: 1.4484573602676392\n",
      "Training: 1 epoch. 2800 iteration. Loss: 1.0196608304977417\n",
      "Training: 1 epoch. 2900 iteration. Loss: 1.275913953781128\n",
      "Training: 1 epoch. 3000 iteration. Loss: 1.2607731819152832\n",
      "Training: 1 epoch. 3100 iteration. Loss: 1.590377926826477\n",
      "Training: 1 epoch. 3200 iteration. Loss: 1.0086455345153809\n",
      "Training: 1 epoch. 3300 iteration. Loss: 1.163354754447937\n",
      "Training: 1 epoch. 3400 iteration. Loss: 1.1904641389846802\n",
      "Training: 1 epoch. 3500 iteration. Loss: 0.44698771834373474\n",
      "Training: 1 epoch. 3600 iteration. Loss: 1.163865566253662\n",
      "Training: 1 epoch. 3700 iteration. Loss: 1.7267976999282837\n",
      "Training loss (ave.): 1.2275078206658363\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.07604876326173544, Accuracy: 0.9815\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 2 epoch. 100 iteration. Loss: 1.351370930671692\n",
      "Training: 2 epoch. 200 iteration. Loss: 1.314086675643921\n",
      "Training: 2 epoch. 300 iteration. Loss: 1.0852043628692627\n",
      "Training: 2 epoch. 400 iteration. Loss: 1.8564205169677734\n",
      "Training: 2 epoch. 500 iteration. Loss: 1.2896994352340698\n",
      "Training: 2 epoch. 600 iteration. Loss: 1.2465519905090332\n",
      "Training: 2 epoch. 700 iteration. Loss: 1.0117573738098145\n",
      "Training: 2 epoch. 800 iteration. Loss: 0.994845986366272\n",
      "Training: 2 epoch. 900 iteration. Loss: 1.626236081123352\n",
      "Training: 2 epoch. 1000 iteration. Loss: 1.165480375289917\n",
      "Training: 2 epoch. 1100 iteration. Loss: 0.6226915121078491\n",
      "Training: 2 epoch. 1200 iteration. Loss: 1.1486538648605347\n",
      "Training: 2 epoch. 1300 iteration. Loss: 1.1748497486114502\n",
      "Training: 2 epoch. 1400 iteration. Loss: 1.8701144456863403\n",
      "Training: 2 epoch. 1500 iteration. Loss: 0.6019852757453918\n",
      "Training: 2 epoch. 1600 iteration. Loss: 0.8660322427749634\n",
      "Training: 2 epoch. 1700 iteration. Loss: 1.027136206626892\n",
      "Training: 2 epoch. 1800 iteration. Loss: 1.290595293045044\n",
      "Training: 2 epoch. 1900 iteration. Loss: 1.603477120399475\n",
      "Training: 2 epoch. 2000 iteration. Loss: 1.2950055599212646\n",
      "Training: 2 epoch. 2100 iteration. Loss: 1.5621405839920044\n",
      "Training: 2 epoch. 2200 iteration. Loss: 0.9579290151596069\n",
      "Training: 2 epoch. 2300 iteration. Loss: 1.1428518295288086\n",
      "Training: 2 epoch. 2400 iteration. Loss: 1.1637502908706665\n",
      "Training: 2 epoch. 2500 iteration. Loss: 1.185654878616333\n",
      "Training: 2 epoch. 2600 iteration. Loss: 1.168482780456543\n",
      "Training: 2 epoch. 2700 iteration. Loss: 1.1699719429016113\n",
      "Training: 2 epoch. 2800 iteration. Loss: 1.388118863105774\n",
      "Training: 2 epoch. 2900 iteration. Loss: 1.010533332824707\n",
      "Training: 2 epoch. 3000 iteration. Loss: 1.73871910572052\n",
      "Training: 2 epoch. 3100 iteration. Loss: 1.1600215435028076\n",
      "Training: 2 epoch. 3200 iteration. Loss: 1.008695363998413\n",
      "Training: 2 epoch. 3300 iteration. Loss: 0.932260274887085\n",
      "Training: 2 epoch. 3400 iteration. Loss: 1.6137853860855103\n",
      "Training: 2 epoch. 3500 iteration. Loss: 0.8661970496177673\n",
      "Training: 2 epoch. 3600 iteration. Loss: 1.0367366075515747\n",
      "Training: 2 epoch. 3700 iteration. Loss: 1.16585373878479\n",
      "Training loss (ave.): 1.1888853398243586\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.09102343635633588, Accuracy: 0.9756\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 3 epoch. 100 iteration. Loss: 1.428388237953186\n",
      "Training: 3 epoch. 200 iteration. Loss: 1.3077231645584106\n",
      "Training: 3 epoch. 300 iteration. Loss: 1.14054274559021\n",
      "Training: 3 epoch. 400 iteration. Loss: 1.0517867803573608\n",
      "Training: 3 epoch. 500 iteration. Loss: 1.985802173614502\n",
      "Training: 3 epoch. 600 iteration. Loss: 1.4228191375732422\n",
      "Training: 3 epoch. 700 iteration. Loss: 0.8741093277931213\n",
      "Training: 3 epoch. 800 iteration. Loss: 1.1582788228988647\n",
      "Training: 3 epoch. 900 iteration. Loss: 1.2239657640457153\n",
      "Training: 3 epoch. 1000 iteration. Loss: 1.3493274450302124\n",
      "Training: 3 epoch. 1100 iteration. Loss: 1.441042423248291\n",
      "Training: 3 epoch. 1200 iteration. Loss: 0.8626604080200195\n",
      "Training: 3 epoch. 1300 iteration. Loss: 1.5734779834747314\n",
      "Training: 3 epoch. 1400 iteration. Loss: 1.2807477712631226\n",
      "Training: 3 epoch. 1500 iteration. Loss: 1.2803438901901245\n",
      "Training: 3 epoch. 1600 iteration. Loss: 1.2357515096664429\n",
      "Training: 3 epoch. 1700 iteration. Loss: 1.2798460721969604\n",
      "Training: 3 epoch. 1800 iteration. Loss: 1.0097393989562988\n",
      "Training: 3 epoch. 1900 iteration. Loss: 1.1410281658172607\n",
      "Training: 3 epoch. 2000 iteration. Loss: 1.0058557987213135\n",
      "Training: 3 epoch. 2100 iteration. Loss: 0.7152556777000427\n",
      "Training: 3 epoch. 2200 iteration. Loss: 0.5767602920532227\n",
      "Training: 3 epoch. 2300 iteration. Loss: 0.4378356635570526\n",
      "Training: 3 epoch. 2400 iteration. Loss: 0.43564677238464355\n",
      "Training: 3 epoch. 2500 iteration. Loss: 0.8697186708450317\n",
      "Training: 3 epoch. 2600 iteration. Loss: 1.4006431102752686\n",
      "Training: 3 epoch. 2700 iteration. Loss: 1.154994010925293\n",
      "Training: 3 epoch. 2800 iteration. Loss: 1.4499152898788452\n",
      "Training: 3 epoch. 2900 iteration. Loss: 1.0129613876342773\n",
      "Training: 3 epoch. 3000 iteration. Loss: 1.0063611268997192\n",
      "Training: 3 epoch. 3100 iteration. Loss: 1.4464876651763916\n",
      "Training: 3 epoch. 3200 iteration. Loss: 1.1628303527832031\n",
      "Training: 3 epoch. 3300 iteration. Loss: 1.4232724905014038\n",
      "Training: 3 epoch. 3400 iteration. Loss: 1.2756500244140625\n",
      "Training: 3 epoch. 3500 iteration. Loss: 1.1951282024383545\n",
      "Training: 3 epoch. 3600 iteration. Loss: 1.3263254165649414\n",
      "Training: 3 epoch. 3700 iteration. Loss: 1.1632275581359863\n",
      "Training loss (ave.): 1.1832273492097856\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.05766138045862317, Accuracy: 0.986\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 4 epoch. 100 iteration. Loss: 1.144317865371704\n",
      "Training: 4 epoch. 200 iteration. Loss: 1.3120965957641602\n",
      "Training: 4 epoch. 300 iteration. Loss: 0.8507121801376343\n",
      "Training: 4 epoch. 400 iteration. Loss: 0.7959215044975281\n",
      "Training: 4 epoch. 500 iteration. Loss: 1.1526126861572266\n",
      "Training: 4 epoch. 600 iteration. Loss: 0.714526891708374\n",
      "Training: 4 epoch. 700 iteration. Loss: 1.4370495080947876\n",
      "Training: 4 epoch. 800 iteration. Loss: 1.2986208200454712\n",
      "Training: 4 epoch. 900 iteration. Loss: 1.1721481084823608\n",
      "Training: 4 epoch. 1000 iteration. Loss: 0.8470971584320068\n",
      "Training: 4 epoch. 1100 iteration. Loss: 1.2945834398269653\n",
      "Training: 4 epoch. 1200 iteration. Loss: 1.1493407487869263\n",
      "Training: 4 epoch. 1300 iteration. Loss: 1.419716477394104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4 epoch. 1400 iteration. Loss: 1.2751988172531128\n",
      "Training: 4 epoch. 1500 iteration. Loss: 0.8559070825576782\n",
      "Training: 4 epoch. 1600 iteration. Loss: 1.3100463151931763\n",
      "Training: 4 epoch. 1700 iteration. Loss: 1.4364336729049683\n",
      "Training: 4 epoch. 1800 iteration. Loss: 1.439193606376648\n",
      "Training: 4 epoch. 1900 iteration. Loss: 1.2894011735916138\n",
      "Training: 4 epoch. 2000 iteration. Loss: 1.440033197402954\n",
      "Training: 4 epoch. 2100 iteration. Loss: 1.138810396194458\n",
      "Training: 4 epoch. 2200 iteration. Loss: 0.707850456237793\n",
      "Training: 4 epoch. 2300 iteration. Loss: 1.1457116603851318\n",
      "Training: 4 epoch. 2400 iteration. Loss: 1.0316787958145142\n",
      "Training: 4 epoch. 2500 iteration. Loss: 1.4759478569030762\n",
      "Training: 4 epoch. 2600 iteration. Loss: 0.9990009069442749\n",
      "Training: 4 epoch. 2700 iteration. Loss: 0.5683724284172058\n",
      "Training: 4 epoch. 2800 iteration. Loss: 1.0384012460708618\n",
      "Training: 4 epoch. 2900 iteration. Loss: 1.7201122045516968\n",
      "Training: 4 epoch. 3000 iteration. Loss: 1.0528907775878906\n",
      "Training: 4 epoch. 3100 iteration. Loss: 0.8702532649040222\n",
      "Training: 4 epoch. 3200 iteration. Loss: 1.0040501356124878\n",
      "Training: 4 epoch. 3300 iteration. Loss: 1.0096211433410645\n",
      "Training: 4 epoch. 3400 iteration. Loss: 0.8756073117256165\n",
      "Training: 4 epoch. 3500 iteration. Loss: 1.1620980501174927\n",
      "Training: 4 epoch. 3600 iteration. Loss: 0.8703873753547668\n",
      "Training: 4 epoch. 3700 iteration. Loss: 1.2948508262634277\n",
      "Training loss (ave.): 1.1786828721721967\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.05966452540755272, Accuracy: 0.9865\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 5 epoch. 100 iteration. Loss: 1.1710760593414307\n",
      "Training: 5 epoch. 200 iteration. Loss: 1.3049553632736206\n",
      "Training: 5 epoch. 300 iteration. Loss: 1.01082181930542\n",
      "Training: 5 epoch. 400 iteration. Loss: 1.1501482725143433\n",
      "Training: 5 epoch. 500 iteration. Loss: 1.1499296426773071\n",
      "Training: 5 epoch. 600 iteration. Loss: 0.7016857862472534\n",
      "Training: 5 epoch. 700 iteration. Loss: 0.5795345902442932\n",
      "Training: 5 epoch. 800 iteration. Loss: 1.1518750190734863\n",
      "Training: 5 epoch. 900 iteration. Loss: 1.003212571144104\n",
      "Training: 5 epoch. 1000 iteration. Loss: 0.8624232411384583\n",
      "Training: 5 epoch. 1100 iteration. Loss: 1.130199909210205\n",
      "Training: 5 epoch. 1200 iteration. Loss: 1.2868657112121582\n",
      "Training: 5 epoch. 1300 iteration. Loss: 0.9915307760238647\n",
      "Training: 5 epoch. 1400 iteration. Loss: 0.8948233127593994\n",
      "Training: 5 epoch. 1500 iteration. Loss: 1.4488753080368042\n",
      "Training: 5 epoch. 1600 iteration. Loss: 1.163253664970398\n",
      "Training: 5 epoch. 1700 iteration. Loss: 1.0432325601577759\n",
      "Training: 5 epoch. 1800 iteration. Loss: 1.1527445316314697\n",
      "Training: 5 epoch. 1900 iteration. Loss: 1.887066125869751\n",
      "Training: 5 epoch. 2000 iteration. Loss: 1.3023320436477661\n",
      "Training: 5 epoch. 2100 iteration. Loss: 1.1512521505355835\n",
      "Training: 5 epoch. 2200 iteration. Loss: 0.5896610021591187\n",
      "Training: 5 epoch. 2300 iteration. Loss: 1.152437448501587\n",
      "Training: 5 epoch. 2400 iteration. Loss: 1.0204594135284424\n",
      "Training: 5 epoch. 2500 iteration. Loss: 0.7070189118385315\n",
      "Training: 5 epoch. 2600 iteration. Loss: 0.8662593364715576\n",
      "Training: 5 epoch. 2700 iteration. Loss: 1.0200071334838867\n",
      "Training: 5 epoch. 2800 iteration. Loss: 1.4239771366119385\n",
      "Training: 5 epoch. 2900 iteration. Loss: 1.591789722442627\n",
      "Training: 5 epoch. 3000 iteration. Loss: 1.146138310432434\n",
      "Training: 5 epoch. 3100 iteration. Loss: 1.3002209663391113\n",
      "Training: 5 epoch. 3200 iteration. Loss: 1.4537960290908813\n",
      "Training: 5 epoch. 3300 iteration. Loss: 0.9947041273117065\n",
      "Training: 5 epoch. 3400 iteration. Loss: 1.0015066862106323\n",
      "Training: 5 epoch. 3500 iteration. Loss: 1.1653093099594116\n",
      "Training: 5 epoch. 3600 iteration. Loss: 1.356772780418396\n",
      "Training: 5 epoch. 3700 iteration. Loss: 1.4902303218841553\n",
      "Training loss (ave.): 1.1596085717956226\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.047722249329462646, Accuracy: 0.9877\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 6 epoch. 100 iteration. Loss: 1.1452548503875732\n",
      "Training: 6 epoch. 200 iteration. Loss: 1.2918429374694824\n",
      "Training: 6 epoch. 300 iteration. Loss: 1.2915514707565308\n",
      "Training: 6 epoch. 400 iteration. Loss: 1.5772113800048828\n",
      "Training: 6 epoch. 500 iteration. Loss: 1.1593252420425415\n",
      "Training: 6 epoch. 600 iteration. Loss: 1.4443494081497192\n",
      "Training: 6 epoch. 700 iteration. Loss: 1.3084638118743896\n",
      "Training: 6 epoch. 800 iteration. Loss: 1.0034748315811157\n",
      "Training: 6 epoch. 900 iteration. Loss: 1.5875332355499268\n",
      "Training: 6 epoch. 1000 iteration. Loss: 0.9928142428398132\n",
      "Training: 6 epoch. 1100 iteration. Loss: 1.281358242034912\n",
      "Training: 6 epoch. 1200 iteration. Loss: 0.7270774841308594\n",
      "Training: 6 epoch. 1300 iteration. Loss: 0.8655880689620972\n",
      "Training: 6 epoch. 1400 iteration. Loss: 0.9951453804969788\n",
      "Training: 6 epoch. 1500 iteration. Loss: 1.1550103425979614\n",
      "Training: 6 epoch. 1600 iteration. Loss: 1.5954382419586182\n",
      "Training: 6 epoch. 1700 iteration. Loss: 1.7616386413574219\n",
      "Training: 6 epoch. 1800 iteration. Loss: 1.0271551609039307\n",
      "Training: 6 epoch. 1900 iteration. Loss: 1.0124338865280151\n",
      "Training: 6 epoch. 2000 iteration. Loss: 1.4491690397262573\n",
      "Training: 6 epoch. 2100 iteration. Loss: 1.8741518259048462\n",
      "Training: 6 epoch. 2200 iteration. Loss: 1.0732060670852661\n",
      "Training: 6 epoch. 2300 iteration. Loss: 0.8623764514923096\n",
      "Training: 6 epoch. 2400 iteration. Loss: 1.1281354427337646\n",
      "Training: 6 epoch. 2500 iteration. Loss: 1.2966370582580566\n",
      "Training: 6 epoch. 2600 iteration. Loss: 1.0377188920974731\n",
      "Training: 6 epoch. 2700 iteration. Loss: 1.0102808475494385\n",
      "Training: 6 epoch. 2800 iteration. Loss: 1.4451074600219727\n",
      "Training: 6 epoch. 2900 iteration. Loss: 1.147688865661621\n",
      "Training: 6 epoch. 3000 iteration. Loss: 1.4528329372406006\n",
      "Training: 6 epoch. 3100 iteration. Loss: 1.1345226764678955\n",
      "Training: 6 epoch. 3200 iteration. Loss: 1.3003307580947876\n",
      "Training: 6 epoch. 3300 iteration. Loss: 1.569725751876831\n",
      "Training: 6 epoch. 3400 iteration. Loss: 1.2975642681121826\n",
      "Training: 6 epoch. 3500 iteration. Loss: 1.875462532043457\n",
      "Training: 6 epoch. 3600 iteration. Loss: 1.165908932685852\n",
      "Training: 6 epoch. 3700 iteration. Loss: 1.5810399055480957\n",
      "Training loss (ave.): 1.160643310948213\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.040995642725098876, Accuracy: 0.9881\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 7 epoch. 100 iteration. Loss: 1.2737910747528076\n",
      "Training: 7 epoch. 200 iteration. Loss: 1.1462490558624268\n",
      "Training: 7 epoch. 300 iteration. Loss: 1.4557141065597534\n",
      "Training: 7 epoch. 400 iteration. Loss: 1.5747501850128174\n",
      "Training: 7 epoch. 500 iteration. Loss: 1.0016295909881592\n",
      "Training: 7 epoch. 600 iteration. Loss: 1.0150365829467773\n",
      "Training: 7 epoch. 700 iteration. Loss: 1.3010627031326294\n",
      "Training: 7 epoch. 800 iteration. Loss: 0.8912937641143799\n",
      "Training: 7 epoch. 900 iteration. Loss: 1.4406390190124512\n",
      "Training: 7 epoch. 1000 iteration. Loss: 1.0005751848220825\n",
      "Training: 7 epoch. 1100 iteration. Loss: 1.8770782947540283\n",
      "Training: 7 epoch. 1200 iteration. Loss: 1.1534323692321777\n",
      "Training: 7 epoch. 1300 iteration. Loss: 1.006564736366272\n",
      "Training: 7 epoch. 1400 iteration. Loss: 1.3105233907699585\n",
      "Training: 7 epoch. 1500 iteration. Loss: 0.8558508157730103\n",
      "Training: 7 epoch. 1600 iteration. Loss: 1.1375548839569092\n",
      "Training: 7 epoch. 1700 iteration. Loss: 1.2942405939102173\n",
      "Training: 7 epoch. 1800 iteration. Loss: 1.108500599861145\n",
      "Training: 7 epoch. 1900 iteration. Loss: 0.9835980534553528\n",
      "Training: 7 epoch. 2000 iteration. Loss: 1.436273455619812\n",
      "Training: 7 epoch. 2100 iteration. Loss: 0.8776368498802185\n",
      "Training: 7 epoch. 2200 iteration. Loss: 1.2917132377624512\n",
      "Training: 7 epoch. 2300 iteration. Loss: 1.3655312061309814\n",
      "Training: 7 epoch. 2400 iteration. Loss: 1.2860666513442993\n",
      "Training: 7 epoch. 2500 iteration. Loss: 1.4413992166519165\n",
      "Training: 7 epoch. 2600 iteration. Loss: 1.1513701677322388\n",
      "Training: 7 epoch. 2700 iteration. Loss: 1.1586204767227173\n",
      "Training: 7 epoch. 2800 iteration. Loss: 0.7059757709503174\n",
      "Training: 7 epoch. 2900 iteration. Loss: 1.162158727645874\n",
      "Training: 7 epoch. 3000 iteration. Loss: 0.7246640920639038\n",
      "Training: 7 epoch. 3100 iteration. Loss: 1.6887474060058594\n",
      "Training: 7 epoch. 3200 iteration. Loss: 1.1584712266921997\n",
      "Training: 7 epoch. 3300 iteration. Loss: 1.3132303953170776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 7 epoch. 3400 iteration. Loss: 1.283125400543213\n",
      "Training: 7 epoch. 3500 iteration. Loss: 1.445825457572937\n",
      "Training: 7 epoch. 3600 iteration. Loss: 1.1904295682907104\n",
      "Training: 7 epoch. 3700 iteration. Loss: 1.2970472574234009\n",
      "Training loss (ave.): 1.156145655854543\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.04616776977665722, Accuracy: 0.989\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 8 epoch. 100 iteration. Loss: 1.4646931886672974\n",
      "Training: 8 epoch. 200 iteration. Loss: 1.150313138961792\n",
      "Training: 8 epoch. 300 iteration. Loss: 0.6827976703643799\n",
      "Training: 8 epoch. 400 iteration. Loss: 1.1377274990081787\n",
      "Training: 8 epoch. 500 iteration. Loss: 1.5920052528381348\n",
      "Training: 8 epoch. 600 iteration. Loss: 1.149519920349121\n",
      "Training: 8 epoch. 700 iteration. Loss: 1.002618432044983\n",
      "Training: 8 epoch. 800 iteration. Loss: 1.2829258441925049\n",
      "Training: 8 epoch. 900 iteration. Loss: 0.7160828113555908\n",
      "Training: 8 epoch. 1000 iteration. Loss: 1.0016076564788818\n",
      "Training: 8 epoch. 1100 iteration. Loss: 2.011723756790161\n",
      "Training: 8 epoch. 1200 iteration. Loss: 0.5798311829566956\n",
      "Training: 8 epoch. 1300 iteration. Loss: 1.581302523612976\n",
      "Training: 8 epoch. 1400 iteration. Loss: 1.2919800281524658\n",
      "Training: 8 epoch. 1500 iteration. Loss: 1.4643933773040771\n",
      "Training: 8 epoch. 1600 iteration. Loss: 1.1514525413513184\n",
      "Training: 8 epoch. 1700 iteration. Loss: 1.8684214353561401\n",
      "Training: 8 epoch. 1800 iteration. Loss: 1.7273751497268677\n",
      "Training: 8 epoch. 1900 iteration. Loss: 1.1458847522735596\n",
      "Training: 8 epoch. 2000 iteration. Loss: 1.1506352424621582\n",
      "Training: 8 epoch. 2100 iteration. Loss: 1.4398633241653442\n",
      "Training: 8 epoch. 2200 iteration. Loss: 1.012702226638794\n",
      "Training: 8 epoch. 2300 iteration. Loss: 1.156722903251648\n",
      "Training: 8 epoch. 2400 iteration. Loss: 1.1826817989349365\n",
      "Training: 8 epoch. 2500 iteration. Loss: 1.4222526550292969\n",
      "Training: 8 epoch. 2600 iteration. Loss: 1.29831862449646\n",
      "Training: 8 epoch. 2700 iteration. Loss: 1.009738564491272\n",
      "Training: 8 epoch. 2800 iteration. Loss: 1.4335949420928955\n",
      "Training: 8 epoch. 2900 iteration. Loss: 1.1460644006729126\n",
      "Training: 8 epoch. 3000 iteration. Loss: 1.1435480117797852\n",
      "Training: 8 epoch. 3100 iteration. Loss: 1.3023569583892822\n",
      "Training: 8 epoch. 3200 iteration. Loss: 1.4039363861083984\n",
      "Training: 8 epoch. 3300 iteration. Loss: 0.8543474674224854\n",
      "Training: 8 epoch. 3400 iteration. Loss: 1.139960765838623\n",
      "Training: 8 epoch. 3500 iteration. Loss: 1.4533518552780151\n",
      "Training: 8 epoch. 3600 iteration. Loss: 1.152039885520935\n",
      "Training: 8 epoch. 3700 iteration. Loss: 0.9903839230537415\n",
      "Training loss (ave.): 1.1591077888329824\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.035432204921368976, Accuracy: 0.9888\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 9 epoch. 100 iteration. Loss: 1.445273756980896\n",
      "Training: 9 epoch. 200 iteration. Loss: 1.4454700946807861\n",
      "Training: 9 epoch. 300 iteration. Loss: 1.1749621629714966\n",
      "Training: 9 epoch. 400 iteration. Loss: 1.2972499132156372\n",
      "Training: 9 epoch. 500 iteration. Loss: 1.3101732730865479\n",
      "Training: 9 epoch. 600 iteration. Loss: 0.9985643029212952\n",
      "Training: 9 epoch. 700 iteration. Loss: 1.2320061922073364\n",
      "Training: 9 epoch. 800 iteration. Loss: 0.8796228170394897\n",
      "Training: 9 epoch. 900 iteration. Loss: 1.271735429763794\n",
      "Training: 9 epoch. 1000 iteration. Loss: 1.717888593673706\n",
      "Training: 9 epoch. 1100 iteration. Loss: 1.1439881324768066\n",
      "Training: 9 epoch. 1200 iteration. Loss: 1.0142539739608765\n",
      "Training: 9 epoch. 1300 iteration. Loss: 1.0076547861099243\n",
      "Training: 9 epoch. 1400 iteration. Loss: 0.87910395860672\n",
      "Training: 9 epoch. 1500 iteration. Loss: 1.1482762098312378\n",
      "Training: 9 epoch. 1600 iteration. Loss: 1.1645569801330566\n",
      "Training: 9 epoch. 1700 iteration. Loss: 0.7292216420173645\n",
      "Training: 9 epoch. 1800 iteration. Loss: 1.2893933057785034\n",
      "Training: 9 epoch. 1900 iteration. Loss: 0.8573505878448486\n",
      "Training: 9 epoch. 2000 iteration. Loss: 1.4531079530715942\n",
      "Training: 9 epoch. 2100 iteration. Loss: 1.3194669485092163\n",
      "Training: 9 epoch. 2200 iteration. Loss: 1.152952790260315\n",
      "Training: 9 epoch. 2300 iteration. Loss: 1.0161595344543457\n",
      "Training: 9 epoch. 2400 iteration. Loss: 1.6006075143814087\n",
      "Training: 9 epoch. 2500 iteration. Loss: 1.1482495069503784\n",
      "Training: 9 epoch. 2600 iteration. Loss: 1.0076192617416382\n",
      "Training: 9 epoch. 2700 iteration. Loss: 1.1429214477539062\n",
      "Training: 9 epoch. 2800 iteration. Loss: 0.7204858660697937\n",
      "Training: 9 epoch. 2900 iteration. Loss: 1.1507567167282104\n",
      "Training: 9 epoch. 3000 iteration. Loss: 0.8697184920310974\n",
      "Training: 9 epoch. 3100 iteration. Loss: 0.7198198437690735\n",
      "Training: 9 epoch. 3200 iteration. Loss: 1.5771479606628418\n",
      "Training: 9 epoch. 3300 iteration. Loss: 1.1301960945129395\n",
      "Training: 9 epoch. 3400 iteration. Loss: 1.425761342048645\n",
      "Training: 9 epoch. 3500 iteration. Loss: 1.7142342329025269\n",
      "Training: 9 epoch. 3600 iteration. Loss: 1.1534802913665771\n",
      "Training: 9 epoch. 3700 iteration. Loss: 1.568536400794983\n",
      "Training loss (ave.): 1.1643469157775244\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.04221385205530096, Accuracy: 0.9881\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 10 epoch. 100 iteration. Loss: 1.1572997570037842\n",
      "Training: 10 epoch. 200 iteration. Loss: 0.850721001625061\n",
      "Training: 10 epoch. 300 iteration. Loss: 1.5913636684417725\n",
      "Training: 10 epoch. 400 iteration. Loss: 1.293668270111084\n",
      "Training: 10 epoch. 500 iteration. Loss: 1.3067506551742554\n",
      "Training: 10 epoch. 600 iteration. Loss: 0.8518891334533691\n",
      "Training: 10 epoch. 700 iteration. Loss: 0.573707640171051\n",
      "Training: 10 epoch. 800 iteration. Loss: 1.1528960466384888\n",
      "Training: 10 epoch. 900 iteration. Loss: 1.1491990089416504\n",
      "Training: 10 epoch. 1000 iteration. Loss: 0.8634769916534424\n",
      "Training: 10 epoch. 1100 iteration. Loss: 1.2924163341522217\n",
      "Training: 10 epoch. 1200 iteration. Loss: 1.430904746055603\n",
      "Training: 10 epoch. 1300 iteration. Loss: 1.0089454650878906\n",
      "Training: 10 epoch. 1400 iteration. Loss: 1.1468194723129272\n",
      "Training: 10 epoch. 1500 iteration. Loss: 0.7152242064476013\n",
      "Training: 10 epoch. 1600 iteration. Loss: 1.1508774757385254\n",
      "Training: 10 epoch. 1700 iteration. Loss: 1.0133410692214966\n",
      "Training: 10 epoch. 1800 iteration. Loss: 1.3980786800384521\n",
      "Training: 10 epoch. 1900 iteration. Loss: 1.3022063970565796\n",
      "Training: 10 epoch. 2000 iteration. Loss: 1.0001684427261353\n",
      "Training: 10 epoch. 2100 iteration. Loss: 1.4266858100891113\n",
      "Training: 10 epoch. 2200 iteration. Loss: 0.715864360332489\n",
      "Training: 10 epoch. 2300 iteration. Loss: 1.44203519821167\n",
      "Training: 10 epoch. 2400 iteration. Loss: 1.0024237632751465\n",
      "Training: 10 epoch. 2500 iteration. Loss: 1.445873737335205\n",
      "Training: 10 epoch. 2600 iteration. Loss: 1.310181975364685\n",
      "Training: 10 epoch. 2700 iteration. Loss: 1.2895194292068481\n",
      "Training: 10 epoch. 2800 iteration. Loss: 1.737286925315857\n",
      "Training: 10 epoch. 2900 iteration. Loss: 1.0022852420806885\n",
      "Training: 10 epoch. 3000 iteration. Loss: 1.4540116786956787\n",
      "Training: 10 epoch. 3100 iteration. Loss: 1.4210236072540283\n",
      "Training: 10 epoch. 3200 iteration. Loss: 1.2978105545043945\n",
      "Training: 10 epoch. 3300 iteration. Loss: 1.2911232709884644\n",
      "Training: 10 epoch. 3400 iteration. Loss: 1.004733920097351\n",
      "Training: 10 epoch. 3500 iteration. Loss: 1.4337995052337646\n",
      "Training: 10 epoch. 3600 iteration. Loss: 0.8666654229164124\n",
      "Training: 10 epoch. 3700 iteration. Loss: 0.9976513981819153\n",
      "Training loss (ave.): 1.175867751999696\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.039751016249507665, Accuracy: 0.9883\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 11 epoch. 100 iteration. Loss: 0.8641148209571838\n",
      "Training: 11 epoch. 200 iteration. Loss: 1.3079975843429565\n",
      "Training: 11 epoch. 300 iteration. Loss: 1.2924660444259644\n",
      "Training: 11 epoch. 400 iteration. Loss: 1.4318636655807495\n",
      "Training: 11 epoch. 500 iteration. Loss: 0.8608002066612244\n",
      "Training: 11 epoch. 600 iteration. Loss: 1.30057692527771\n",
      "Training: 11 epoch. 700 iteration. Loss: 1.6048551797866821\n",
      "Training: 11 epoch. 800 iteration. Loss: 1.0054335594177246\n",
      "Training: 11 epoch. 900 iteration. Loss: 1.2998127937316895\n",
      "Training: 11 epoch. 1000 iteration. Loss: 0.7291721105575562\n",
      "Training: 11 epoch. 1100 iteration. Loss: 1.7297024726867676\n",
      "Training: 11 epoch. 1200 iteration. Loss: 0.863983154296875\n",
      "Training: 11 epoch. 1300 iteration. Loss: 1.0067362785339355\n",
      "Training: 11 epoch. 1400 iteration. Loss: 0.7227784395217896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 11 epoch. 1500 iteration. Loss: 1.2969211339950562\n",
      "Training: 11 epoch. 1600 iteration. Loss: 1.1720370054244995\n",
      "Training: 11 epoch. 1700 iteration. Loss: 1.2892135381698608\n",
      "Training: 11 epoch. 1800 iteration. Loss: 1.7398076057434082\n",
      "Training: 11 epoch. 1900 iteration. Loss: 0.9810646772384644\n",
      "Training: 11 epoch. 2000 iteration. Loss: 1.2824382781982422\n",
      "Training: 11 epoch. 2100 iteration. Loss: 1.1658049821853638\n",
      "Training: 11 epoch. 2200 iteration. Loss: 1.2943907976150513\n",
      "Training: 11 epoch. 2300 iteration. Loss: 1.154538869857788\n",
      "Training: 11 epoch. 2400 iteration. Loss: 0.8846167325973511\n",
      "Training: 11 epoch. 2500 iteration. Loss: 1.0050458908081055\n",
      "Training: 11 epoch. 2600 iteration. Loss: 0.4301952123641968\n",
      "Training: 11 epoch. 2700 iteration. Loss: 1.5876471996307373\n",
      "Training: 11 epoch. 2800 iteration. Loss: 0.7190506458282471\n",
      "Training: 11 epoch. 2900 iteration. Loss: 1.2946672439575195\n",
      "Training: 11 epoch. 3000 iteration. Loss: 1.2973052263259888\n",
      "Training: 11 epoch. 3100 iteration. Loss: 1.2914561033248901\n",
      "Training: 11 epoch. 3200 iteration. Loss: 1.300520896911621\n",
      "Training: 11 epoch. 3300 iteration. Loss: 0.6019201278686523\n",
      "Training: 11 epoch. 3400 iteration. Loss: 1.8613227605819702\n",
      "Training: 11 epoch. 3500 iteration. Loss: 1.163849115371704\n",
      "Training: 11 epoch. 3600 iteration. Loss: 1.1667388677597046\n",
      "Training: 11 epoch. 3700 iteration. Loss: 1.1471741199493408\n",
      "Training loss (ave.): 1.1625898105621337\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.04309015517409425, Accuracy: 0.9865\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 12 epoch. 100 iteration. Loss: 0.7230954170227051\n",
      "Training: 12 epoch. 200 iteration. Loss: 0.8671558499336243\n",
      "Training: 12 epoch. 300 iteration. Loss: 1.4400608539581299\n",
      "Training: 12 epoch. 400 iteration. Loss: 1.0119655132293701\n",
      "Training: 12 epoch. 500 iteration. Loss: 1.4332325458526611\n",
      "Training: 12 epoch. 600 iteration. Loss: 1.451880931854248\n",
      "Training: 12 epoch. 700 iteration. Loss: 1.1511638164520264\n",
      "Training: 12 epoch. 800 iteration. Loss: 1.148596167564392\n",
      "Training: 12 epoch. 900 iteration. Loss: 1.1518586874008179\n",
      "Training: 12 epoch. 1000 iteration. Loss: 1.4446521997451782\n",
      "Training: 12 epoch. 1100 iteration. Loss: 1.1408698558807373\n",
      "Training: 12 epoch. 1200 iteration. Loss: 1.719279408454895\n",
      "Training: 12 epoch. 1300 iteration. Loss: 1.2943570613861084\n",
      "Training: 12 epoch. 1400 iteration. Loss: 0.13820044696331024\n",
      "Training: 12 epoch. 1500 iteration. Loss: 1.3046016693115234\n",
      "Training: 12 epoch. 1600 iteration. Loss: 0.8747959136962891\n",
      "Training: 12 epoch. 1700 iteration. Loss: 1.5968972444534302\n",
      "Training: 12 epoch. 1800 iteration. Loss: 1.2934476137161255\n",
      "Training: 12 epoch. 1900 iteration. Loss: 1.5809931755065918\n",
      "Training: 12 epoch. 2000 iteration. Loss: 1.1559947729110718\n",
      "Training: 12 epoch. 2100 iteration. Loss: 1.290210485458374\n",
      "Training: 12 epoch. 2200 iteration. Loss: 0.8714066743850708\n",
      "Training: 12 epoch. 2300 iteration. Loss: 1.1565186977386475\n",
      "Training: 12 epoch. 2400 iteration. Loss: 1.004910945892334\n",
      "Training: 12 epoch. 2500 iteration. Loss: 1.444662094116211\n",
      "Training: 12 epoch. 2600 iteration. Loss: 1.0060129165649414\n",
      "Training: 12 epoch. 2700 iteration. Loss: 0.7243990898132324\n",
      "Training: 12 epoch. 2800 iteration. Loss: 1.041373372077942\n",
      "Training: 12 epoch. 2900 iteration. Loss: 1.0061529874801636\n",
      "Training: 12 epoch. 3000 iteration. Loss: 1.1294975280761719\n",
      "Training: 12 epoch. 3100 iteration. Loss: 1.1391698122024536\n",
      "Training: 12 epoch. 3200 iteration. Loss: 0.8615642189979553\n",
      "Training: 12 epoch. 3300 iteration. Loss: 0.8755679130554199\n",
      "Training: 12 epoch. 3400 iteration. Loss: 1.1446056365966797\n",
      "Training: 12 epoch. 3500 iteration. Loss: 0.9770005941390991\n",
      "Training: 12 epoch. 3600 iteration. Loss: 1.010724663734436\n",
      "Training: 12 epoch. 3700 iteration. Loss: 1.2930347919464111\n",
      "Training loss (ave.): 1.1630458153247833\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.052930704272804725, Accuracy: 0.9844\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 13 epoch. 100 iteration. Loss: 1.4665236473083496\n",
      "Training: 13 epoch. 200 iteration. Loss: 1.2763499021530151\n",
      "Training: 13 epoch. 300 iteration. Loss: 0.7132402658462524\n",
      "Training: 13 epoch. 400 iteration. Loss: 1.426337718963623\n",
      "Training: 13 epoch. 500 iteration. Loss: 0.7245768308639526\n",
      "Training: 13 epoch. 600 iteration. Loss: 0.7179240584373474\n",
      "Training: 13 epoch. 700 iteration. Loss: 1.1482075452804565\n",
      "Training: 13 epoch. 800 iteration. Loss: 1.290710687637329\n",
      "Training: 13 epoch. 900 iteration. Loss: 1.4305825233459473\n",
      "Training: 13 epoch. 1000 iteration. Loss: 0.8568134903907776\n",
      "Training: 13 epoch. 1100 iteration. Loss: 1.2950797080993652\n",
      "Training: 13 epoch. 1200 iteration. Loss: 1.30216646194458\n",
      "Training: 13 epoch. 1300 iteration. Loss: 1.1484012603759766\n",
      "Training: 13 epoch. 1400 iteration. Loss: 1.7553768157958984\n",
      "Training: 13 epoch. 1500 iteration. Loss: 1.447601318359375\n",
      "Training: 13 epoch. 1600 iteration. Loss: 1.2951399087905884\n",
      "Training: 13 epoch. 1700 iteration. Loss: 1.5783350467681885\n",
      "Training: 13 epoch. 1800 iteration. Loss: 1.5744093656539917\n",
      "Training: 13 epoch. 1900 iteration. Loss: 1.2986551523208618\n",
      "Training: 13 epoch. 2000 iteration. Loss: 1.590541124343872\n",
      "Training: 13 epoch. 2100 iteration. Loss: 1.0088605880737305\n",
      "Training: 13 epoch. 2200 iteration. Loss: 1.1440811157226562\n",
      "Training: 13 epoch. 2300 iteration. Loss: 1.4457885026931763\n",
      "Training: 13 epoch. 2400 iteration. Loss: 1.2903475761413574\n",
      "Training: 13 epoch. 2500 iteration. Loss: 0.8588532209396362\n",
      "Training: 13 epoch. 2600 iteration. Loss: 0.5846014022827148\n",
      "Training: 13 epoch. 2700 iteration. Loss: 0.9984281063079834\n",
      "Training: 13 epoch. 2800 iteration. Loss: 1.1490528583526611\n",
      "Training: 13 epoch. 2900 iteration. Loss: 1.5845376253128052\n",
      "Training: 13 epoch. 3000 iteration. Loss: 1.0098119974136353\n",
      "Training: 13 epoch. 3100 iteration. Loss: 0.8862165808677673\n",
      "Training: 13 epoch. 3200 iteration. Loss: 1.8747081756591797\n",
      "Training: 13 epoch. 3300 iteration. Loss: 1.3099042177200317\n",
      "Training: 13 epoch. 3400 iteration. Loss: 0.8609079122543335\n",
      "Training: 13 epoch. 3500 iteration. Loss: 1.142283320426941\n",
      "Training: 13 epoch. 3600 iteration. Loss: 1.0069712400436401\n",
      "Training: 13 epoch. 3700 iteration. Loss: 1.5931116342544556\n",
      "Training loss (ave.): 1.166880505088965\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.034069501896953444, Accuracy: 0.9889\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 14 epoch. 100 iteration. Loss: 1.4270466566085815\n",
      "Training: 14 epoch. 200 iteration. Loss: 0.87250816822052\n",
      "Training: 14 epoch. 300 iteration. Loss: 0.8656650185585022\n",
      "Training: 14 epoch. 400 iteration. Loss: 1.294779658317566\n",
      "Training: 14 epoch. 500 iteration. Loss: 1.5908111333847046\n",
      "Training: 14 epoch. 600 iteration. Loss: 1.152416467666626\n",
      "Training: 14 epoch. 700 iteration. Loss: 1.0003588199615479\n",
      "Training: 14 epoch. 800 iteration. Loss: 1.4369975328445435\n",
      "Training: 14 epoch. 900 iteration. Loss: 1.286803960800171\n",
      "Training: 14 epoch. 1000 iteration. Loss: 1.1526408195495605\n",
      "Training: 14 epoch. 1100 iteration. Loss: 1.720468521118164\n",
      "Training: 14 epoch. 1200 iteration. Loss: 1.3176286220550537\n",
      "Training: 14 epoch. 1300 iteration. Loss: 0.2863975763320923\n",
      "Training: 14 epoch. 1400 iteration. Loss: 1.5747442245483398\n",
      "Training: 14 epoch. 1500 iteration. Loss: 0.9983403086662292\n",
      "Training: 14 epoch. 1600 iteration. Loss: 1.011025309562683\n",
      "Training: 14 epoch. 1700 iteration. Loss: 1.2836222648620605\n",
      "Training: 14 epoch. 1800 iteration. Loss: 1.5948601961135864\n",
      "Training: 14 epoch. 1900 iteration. Loss: 1.4535868167877197\n",
      "Training: 14 epoch. 2000 iteration. Loss: 1.294938325881958\n",
      "Training: 14 epoch. 2100 iteration. Loss: 0.8541292548179626\n",
      "Training: 14 epoch. 2200 iteration. Loss: 0.5809937119483948\n",
      "Training: 14 epoch. 2300 iteration. Loss: 1.008086919784546\n",
      "Training: 14 epoch. 2400 iteration. Loss: 1.2939521074295044\n",
      "Training: 14 epoch. 2500 iteration. Loss: 1.3137269020080566\n",
      "Training: 14 epoch. 2600 iteration. Loss: 1.1507781744003296\n",
      "Training: 14 epoch. 2700 iteration. Loss: 1.3108121156692505\n",
      "Training: 14 epoch. 2800 iteration. Loss: 0.8582179546356201\n",
      "Training: 14 epoch. 2900 iteration. Loss: 1.0128756761550903\n",
      "Training: 14 epoch. 3000 iteration. Loss: 1.000422716140747\n",
      "Training: 14 epoch. 3100 iteration. Loss: 1.7287273406982422\n",
      "Training: 14 epoch. 3200 iteration. Loss: 1.0070695877075195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 14 epoch. 3300 iteration. Loss: 1.0033739805221558\n",
      "Training: 14 epoch. 3400 iteration. Loss: 0.8741610646247864\n",
      "Training: 14 epoch. 3500 iteration. Loss: 1.732736349105835\n",
      "Training: 14 epoch. 3600 iteration. Loss: 0.5811918377876282\n",
      "Training: 14 epoch. 3700 iteration. Loss: 1.0238748788833618\n",
      "Training loss (ave.): 1.163176219391823\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.03852062488661613, Accuracy: 0.9881\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 15 epoch. 100 iteration. Loss: 1.284419059753418\n",
      "Training: 15 epoch. 200 iteration. Loss: 0.9916567206382751\n",
      "Training: 15 epoch. 300 iteration. Loss: 0.720686137676239\n",
      "Training: 15 epoch. 400 iteration. Loss: 0.8487247228622437\n",
      "Training: 15 epoch. 500 iteration. Loss: 1.2901617288589478\n",
      "Training: 15 epoch. 600 iteration. Loss: 0.8702069520950317\n",
      "Training: 15 epoch. 700 iteration. Loss: 1.3001123666763306\n",
      "Training: 15 epoch. 800 iteration. Loss: 0.9916138052940369\n",
      "Training: 15 epoch. 900 iteration. Loss: 1.1587681770324707\n",
      "Training: 15 epoch. 1000 iteration. Loss: 0.881170392036438\n",
      "Training: 15 epoch. 1100 iteration. Loss: 0.855675458908081\n",
      "Training: 15 epoch. 1200 iteration. Loss: 1.167450189590454\n",
      "Training: 15 epoch. 1300 iteration. Loss: 1.1315984725952148\n",
      "Training: 15 epoch. 1400 iteration. Loss: 1.1504004001617432\n",
      "Training: 15 epoch. 1500 iteration. Loss: 1.3055675029754639\n",
      "Training: 15 epoch. 1600 iteration. Loss: 1.1618760824203491\n",
      "Training: 15 epoch. 1700 iteration. Loss: 0.7500548362731934\n",
      "Training: 15 epoch. 1800 iteration. Loss: 1.4391958713531494\n",
      "Training: 15 epoch. 1900 iteration. Loss: 1.4254498481750488\n",
      "Training: 15 epoch. 2000 iteration. Loss: 1.7308142185211182\n",
      "Training: 15 epoch. 2100 iteration. Loss: 0.7097401022911072\n",
      "Training: 15 epoch. 2200 iteration. Loss: 1.4406719207763672\n",
      "Training: 15 epoch. 2300 iteration. Loss: 1.2800970077514648\n",
      "Training: 15 epoch. 2400 iteration. Loss: 1.2938413619995117\n",
      "Training: 15 epoch. 2500 iteration. Loss: 0.7122763395309448\n",
      "Training: 15 epoch. 2600 iteration. Loss: 1.4374467134475708\n",
      "Training: 15 epoch. 2700 iteration. Loss: 1.0114644765853882\n",
      "Training: 15 epoch. 2800 iteration. Loss: 0.9983718395233154\n",
      "Training: 15 epoch. 2900 iteration. Loss: 0.7121623754501343\n",
      "Training: 15 epoch. 3000 iteration. Loss: 1.1444066762924194\n",
      "Training: 15 epoch. 3100 iteration. Loss: 1.443639874458313\n",
      "Training: 15 epoch. 3200 iteration. Loss: 1.4715520143508911\n",
      "Training: 15 epoch. 3300 iteration. Loss: 0.7176750302314758\n",
      "Training: 15 epoch. 3400 iteration. Loss: 1.0080240964889526\n",
      "Training: 15 epoch. 3500 iteration. Loss: 0.8690845370292664\n",
      "Training: 15 epoch. 3600 iteration. Loss: 1.288321852684021\n",
      "Training: 15 epoch. 3700 iteration. Loss: 1.0036944150924683\n",
      "Training loss (ave.): 1.1547514256079991\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.0460938638415435, Accuracy: 0.9872\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 16 epoch. 100 iteration. Loss: 1.294023871421814\n",
      "Training: 16 epoch. 200 iteration. Loss: 1.150285005569458\n",
      "Training: 16 epoch. 300 iteration. Loss: 1.1398568153381348\n",
      "Training: 16 epoch. 400 iteration. Loss: 0.7281965613365173\n",
      "Training: 16 epoch. 500 iteration. Loss: 0.8674780130386353\n",
      "Training: 16 epoch. 600 iteration. Loss: 1.4304590225219727\n",
      "Training: 16 epoch. 700 iteration. Loss: 1.4409551620483398\n",
      "Training: 16 epoch. 800 iteration. Loss: 0.566335916519165\n",
      "Training: 16 epoch. 900 iteration. Loss: 1.1315746307373047\n",
      "Training: 16 epoch. 1000 iteration. Loss: 0.8703712224960327\n",
      "Training: 16 epoch. 1100 iteration. Loss: 1.3048042058944702\n",
      "Training: 16 epoch. 1200 iteration. Loss: 0.7161211967468262\n",
      "Training: 16 epoch. 1300 iteration. Loss: 0.85695880651474\n",
      "Training: 16 epoch. 1400 iteration. Loss: 0.8711292147636414\n",
      "Training: 16 epoch. 1500 iteration. Loss: 0.7163184881210327\n",
      "Training: 16 epoch. 1600 iteration. Loss: 1.5615592002868652\n",
      "Training: 16 epoch. 1700 iteration. Loss: 1.1478826999664307\n",
      "Training: 16 epoch. 1800 iteration. Loss: 1.574939489364624\n",
      "Training: 16 epoch. 1900 iteration. Loss: 1.5963231325149536\n",
      "Training: 16 epoch. 2000 iteration. Loss: 1.0114526748657227\n",
      "Training: 16 epoch. 2100 iteration. Loss: 1.2951090335845947\n",
      "Training: 16 epoch. 2200 iteration. Loss: 0.43731003999710083\n",
      "Training: 16 epoch. 2300 iteration. Loss: 1.0038373470306396\n",
      "Training: 16 epoch. 2400 iteration. Loss: 0.730411946773529\n",
      "Training: 16 epoch. 2500 iteration. Loss: 1.2895010709762573\n",
      "Training: 16 epoch. 2600 iteration. Loss: 1.154929518699646\n",
      "Training: 16 epoch. 2700 iteration. Loss: 1.011514663696289\n",
      "Training: 16 epoch. 2800 iteration. Loss: 1.4498552083969116\n",
      "Training: 16 epoch. 2900 iteration. Loss: 1.0152865648269653\n",
      "Training: 16 epoch. 3000 iteration. Loss: 1.0113916397094727\n",
      "Training: 16 epoch. 3100 iteration. Loss: 1.5881400108337402\n",
      "Training: 16 epoch. 3200 iteration. Loss: 0.8747084140777588\n",
      "Training: 16 epoch. 3300 iteration. Loss: 0.5697324275970459\n",
      "Training: 16 epoch. 3400 iteration. Loss: 1.5885670185089111\n",
      "Training: 16 epoch. 3500 iteration. Loss: 1.571513056755066\n",
      "Training: 16 epoch. 3600 iteration. Loss: 0.8717830181121826\n",
      "Training: 16 epoch. 3700 iteration. Loss: 1.2953556776046753\n",
      "Training loss (ave.): 1.1600767350792884\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.047528511526301005, Accuracy: 0.9871\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 17 epoch. 100 iteration. Loss: 1.0124272108078003\n",
      "Training: 17 epoch. 200 iteration. Loss: 1.2893303632736206\n",
      "Training: 17 epoch. 300 iteration. Loss: 0.7329509854316711\n",
      "Training: 17 epoch. 400 iteration. Loss: 1.4285434484481812\n",
      "Training: 17 epoch. 500 iteration. Loss: 1.3085325956344604\n",
      "Training: 17 epoch. 600 iteration. Loss: 1.0107474327087402\n",
      "Training: 17 epoch. 700 iteration. Loss: 1.295166015625\n",
      "Training: 17 epoch. 800 iteration. Loss: 1.005831241607666\n",
      "Training: 17 epoch. 900 iteration. Loss: 1.5882987976074219\n",
      "Training: 17 epoch. 1000 iteration. Loss: 1.3077080249786377\n",
      "Training: 17 epoch. 1100 iteration. Loss: 1.0019409656524658\n",
      "Training: 17 epoch. 1200 iteration. Loss: 1.2928532361984253\n",
      "Training: 17 epoch. 1300 iteration. Loss: 1.1467657089233398\n",
      "Training: 17 epoch. 1400 iteration. Loss: 1.7289197444915771\n",
      "Training: 17 epoch. 1500 iteration. Loss: 0.8537710905075073\n",
      "Training: 17 epoch. 1600 iteration. Loss: 1.2953877449035645\n",
      "Training: 17 epoch. 1700 iteration. Loss: 1.4330620765686035\n",
      "Training: 17 epoch. 1800 iteration. Loss: 0.8639835119247437\n",
      "Training: 17 epoch. 1900 iteration. Loss: 1.5882329940795898\n",
      "Training: 17 epoch. 2000 iteration. Loss: 1.14739191532135\n",
      "Training: 17 epoch. 2100 iteration. Loss: 1.3363113403320312\n",
      "Training: 17 epoch. 2200 iteration. Loss: 0.8530930280685425\n",
      "Training: 17 epoch. 2300 iteration. Loss: 1.582158088684082\n",
      "Training: 17 epoch. 2400 iteration. Loss: 1.158913254737854\n",
      "Training: 17 epoch. 2500 iteration. Loss: 1.1465948820114136\n",
      "Training: 17 epoch. 2600 iteration. Loss: 1.586979627609253\n",
      "Training: 17 epoch. 2700 iteration. Loss: 1.153670310974121\n",
      "Training: 17 epoch. 2800 iteration. Loss: 1.4298748970031738\n",
      "Training: 17 epoch. 2900 iteration. Loss: 1.3075189590454102\n",
      "Training: 17 epoch. 3000 iteration. Loss: 1.2989113330841064\n",
      "Training: 17 epoch. 3100 iteration. Loss: 0.9921360015869141\n",
      "Training: 17 epoch. 3200 iteration. Loss: 1.7076658010482788\n",
      "Training: 17 epoch. 3300 iteration. Loss: 1.1354665756225586\n",
      "Training: 17 epoch. 3400 iteration. Loss: 0.8519855737686157\n",
      "Training: 17 epoch. 3500 iteration. Loss: 1.5764487981796265\n",
      "Training: 17 epoch. 3600 iteration. Loss: 0.862353503704071\n",
      "Training: 17 epoch. 3700 iteration. Loss: 1.1481820344924927\n",
      "Training loss (ave.): 1.152509929450353\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.03585016366607997, Accuracy: 0.9896\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 18 epoch. 100 iteration. Loss: 1.5908235311508179\n",
      "Training: 18 epoch. 200 iteration. Loss: 1.2991530895233154\n",
      "Training: 18 epoch. 300 iteration. Loss: 1.886221170425415\n",
      "Training: 18 epoch. 400 iteration. Loss: 1.1383599042892456\n",
      "Training: 18 epoch. 500 iteration. Loss: 0.8804971575737\n",
      "Training: 18 epoch. 600 iteration. Loss: 0.8664242029190063\n",
      "Training: 18 epoch. 700 iteration. Loss: 1.5735046863555908\n",
      "Training: 18 epoch. 800 iteration. Loss: 0.8579279184341431\n",
      "Training: 18 epoch. 900 iteration. Loss: 1.2705479860305786\n",
      "Training: 18 epoch. 1000 iteration. Loss: 0.8574238419532776\n",
      "Training: 18 epoch. 1100 iteration. Loss: 1.4334200620651245\n",
      "Training: 18 epoch. 1200 iteration. Loss: 1.2143967151641846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 18 epoch. 1300 iteration. Loss: 1.0423097610473633\n",
      "Training: 18 epoch. 1400 iteration. Loss: 0.8735753297805786\n",
      "Training: 18 epoch. 1500 iteration. Loss: 1.01124906539917\n",
      "Training: 18 epoch. 1600 iteration. Loss: 0.8662155866622925\n",
      "Training: 18 epoch. 1700 iteration. Loss: 0.8517535328865051\n",
      "Training: 18 epoch. 1800 iteration. Loss: 0.8743498921394348\n",
      "Training: 18 epoch. 1900 iteration. Loss: 1.2803850173950195\n",
      "Training: 18 epoch. 2000 iteration. Loss: 1.3041647672653198\n",
      "Training: 18 epoch. 2100 iteration. Loss: 1.5853333473205566\n",
      "Training: 18 epoch. 2200 iteration. Loss: 1.2969589233398438\n",
      "Training: 18 epoch. 2300 iteration. Loss: 1.458199143409729\n",
      "Training: 18 epoch. 2400 iteration. Loss: 1.4305802583694458\n",
      "Training: 18 epoch. 2500 iteration. Loss: 1.1553086042404175\n",
      "Training: 18 epoch. 2600 iteration. Loss: 1.1495518684387207\n",
      "Training: 18 epoch. 2700 iteration. Loss: 1.1370322704315186\n",
      "Training: 18 epoch. 2800 iteration. Loss: 1.449079990386963\n",
      "Training: 18 epoch. 2900 iteration. Loss: 1.1520906686782837\n",
      "Training: 18 epoch. 3000 iteration. Loss: 1.3011234998703003\n",
      "Training: 18 epoch. 3100 iteration. Loss: 0.7051105499267578\n",
      "Training: 18 epoch. 3200 iteration. Loss: 1.1482168436050415\n",
      "Training: 18 epoch. 3300 iteration. Loss: 0.8715201616287231\n",
      "Training: 18 epoch. 3400 iteration. Loss: 1.000627040863037\n",
      "Training: 18 epoch. 3500 iteration. Loss: 0.8762097954750061\n",
      "Training: 18 epoch. 3600 iteration. Loss: 0.5794511437416077\n",
      "Training: 18 epoch. 3700 iteration. Loss: 0.8667709827423096\n",
      "Training loss (ave.): 1.161169503657023\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.04313321473317337, Accuracy: 0.9881\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 19 epoch. 100 iteration. Loss: 0.7076773047447205\n",
      "Training: 19 epoch. 200 iteration. Loss: 1.1573467254638672\n",
      "Training: 19 epoch. 300 iteration. Loss: 1.2845814228057861\n",
      "Training: 19 epoch. 400 iteration. Loss: 1.2961113452911377\n",
      "Training: 19 epoch. 500 iteration. Loss: 1.295987844467163\n",
      "Training: 19 epoch. 600 iteration. Loss: 1.070069432258606\n",
      "Training: 19 epoch. 700 iteration. Loss: 1.1582781076431274\n",
      "Training: 19 epoch. 800 iteration. Loss: 1.4384679794311523\n",
      "Training: 19 epoch. 900 iteration. Loss: 1.4323444366455078\n",
      "Training: 19 epoch. 1000 iteration. Loss: 0.7151778936386108\n",
      "Training: 19 epoch. 1100 iteration. Loss: 1.4168016910552979\n",
      "Training: 19 epoch. 1200 iteration. Loss: 1.1382800340652466\n",
      "Training: 19 epoch. 1300 iteration. Loss: 1.3044453859329224\n",
      "Training: 19 epoch. 1400 iteration. Loss: 1.7108896970748901\n",
      "Training: 19 epoch. 1500 iteration. Loss: 1.1502834558486938\n",
      "Training: 19 epoch. 1600 iteration. Loss: 1.1561734676361084\n",
      "Training: 19 epoch. 1700 iteration. Loss: 0.43554186820983887\n",
      "Training: 19 epoch. 1800 iteration. Loss: 0.8556823134422302\n",
      "Training: 19 epoch. 1900 iteration. Loss: 1.4160966873168945\n",
      "Training: 19 epoch. 2000 iteration. Loss: 0.872776210308075\n",
      "Training: 19 epoch. 2100 iteration. Loss: 1.0137693881988525\n",
      "Training: 19 epoch. 2200 iteration. Loss: 1.4468505382537842\n",
      "Training: 19 epoch. 2300 iteration. Loss: 0.7248022556304932\n",
      "Training: 19 epoch. 2400 iteration. Loss: 1.0152032375335693\n",
      "Training: 19 epoch. 2500 iteration. Loss: 1.4383032321929932\n",
      "Training: 19 epoch. 2600 iteration. Loss: 0.8441888093948364\n",
      "Training: 19 epoch. 2700 iteration. Loss: 1.1472291946411133\n",
      "Training: 19 epoch. 2800 iteration. Loss: 1.5733407735824585\n",
      "Training: 19 epoch. 2900 iteration. Loss: 1.2824089527130127\n",
      "Training: 19 epoch. 3000 iteration. Loss: 1.1639282703399658\n",
      "Training: 19 epoch. 3100 iteration. Loss: 1.2836430072784424\n",
      "Training: 19 epoch. 3200 iteration. Loss: 1.139201045036316\n",
      "Training: 19 epoch. 3300 iteration. Loss: 1.1562285423278809\n",
      "Training: 19 epoch. 3400 iteration. Loss: 1.0481927394866943\n",
      "Training: 19 epoch. 3500 iteration. Loss: 1.4378973245620728\n",
      "Training: 19 epoch. 3600 iteration. Loss: 1.0137102603912354\n",
      "Training: 19 epoch. 3700 iteration. Loss: 1.0333248376846313\n",
      "Training loss (ave.): 1.1615230877717335\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.04497452018463996, Accuracy: 0.9898\n",
      "\n",
      "\n",
      "Train start\n",
      "Training: 20 epoch. 100 iteration. Loss: 1.008744478225708\n",
      "Training: 20 epoch. 200 iteration. Loss: 1.2890878915786743\n",
      "Training: 20 epoch. 300 iteration. Loss: 1.5677671432495117\n",
      "Training: 20 epoch. 400 iteration. Loss: 1.2875840663909912\n",
      "Training: 20 epoch. 500 iteration. Loss: 1.2923908233642578\n",
      "Training: 20 epoch. 600 iteration. Loss: 1.8569527864456177\n",
      "Training: 20 epoch. 700 iteration. Loss: 1.006089210510254\n",
      "Training: 20 epoch. 800 iteration. Loss: 1.1348581314086914\n",
      "Training: 20 epoch. 900 iteration. Loss: 1.1653406620025635\n",
      "Training: 20 epoch. 1000 iteration. Loss: 1.3011749982833862\n",
      "Training: 20 epoch. 1100 iteration. Loss: 1.1284406185150146\n",
      "Training: 20 epoch. 1200 iteration. Loss: 1.5785447359085083\n",
      "Training: 20 epoch. 1300 iteration. Loss: 0.8644236922264099\n",
      "Training: 20 epoch. 1400 iteration. Loss: 1.0104390382766724\n",
      "Training: 20 epoch. 1500 iteration. Loss: 0.8618787527084351\n",
      "Training: 20 epoch. 1600 iteration. Loss: 1.4466603994369507\n",
      "Training: 20 epoch. 1700 iteration. Loss: 1.170836091041565\n",
      "Training: 20 epoch. 1800 iteration. Loss: 1.1475310325622559\n",
      "Training: 20 epoch. 1900 iteration. Loss: 1.4419361352920532\n",
      "Training: 20 epoch. 2000 iteration. Loss: 1.5795682668685913\n",
      "Training: 20 epoch. 2100 iteration. Loss: 0.8584370613098145\n",
      "Training: 20 epoch. 2200 iteration. Loss: 1.140149712562561\n",
      "Training: 20 epoch. 2300 iteration. Loss: 0.8503119349479675\n",
      "Training: 20 epoch. 2400 iteration. Loss: 1.5878653526306152\n",
      "Training: 20 epoch. 2500 iteration. Loss: 1.5542552471160889\n",
      "Training: 20 epoch. 2600 iteration. Loss: 1.2860502004623413\n",
      "Training: 20 epoch. 2700 iteration. Loss: 0.8779726028442383\n",
      "Training: 20 epoch. 2800 iteration. Loss: 1.287334680557251\n",
      "Training: 20 epoch. 2900 iteration. Loss: 1.0134913921356201\n",
      "Training: 20 epoch. 3000 iteration. Loss: 1.4217324256896973\n",
      "Training: 20 epoch. 3100 iteration. Loss: 1.2990353107452393\n",
      "Training: 20 epoch. 3200 iteration. Loss: 1.156158208847046\n",
      "Training: 20 epoch. 3300 iteration. Loss: 0.7125329971313477\n",
      "Training: 20 epoch. 3400 iteration. Loss: 1.0040380954742432\n",
      "Training: 20 epoch. 3500 iteration. Loss: 1.0033987760543823\n",
      "Training: 20 epoch. 3600 iteration. Loss: 1.2956552505493164\n",
      "Training: 20 epoch. 3700 iteration. Loss: 1.2807499170303345\n",
      "Training loss (ave.): 1.155395425025622\n",
      "\n",
      "Validation start\n",
      "Validation loss: 0.04477558540102823, Accuracy: 0.9889\n",
      "\n",
      "{'train_loss': [1.2275078206658363, 1.1888853398243586, 1.1832273492097856, 1.1786828721721967, 1.1596085717956226, 1.160643310948213, 1.156145655854543, 1.1591077888329824, 1.1643469157775244, 1.175867751999696, 1.1625898105621337, 1.1630458153247833, 1.166880505088965, 1.163176219391823, 1.1547514256079991, 1.1600767350792884, 1.152509929450353, 1.161169503657023, 1.1615230877717335, 1.155395425025622], 'validation_loss': [0.07604876326173544, 0.09102343635633588, 0.05766138045862317, 0.05966452540755272, 0.047722249329462646, 0.040995642725098876, 0.04616776977665722, 0.035432204921368976, 0.04221385205530096, 0.039751016249507665, 0.04309015517409425, 0.052930704272804725, 0.034069501896953444, 0.03852062488661613, 0.0460938638415435, 0.047528511526301005, 0.03585016366607997, 0.04313321473317337, 0.04497452018463996, 0.04477558540102823], 'validation_acc': [0.9815, 0.9756, 0.986, 0.9865, 0.9877, 0.9881, 0.989, 0.9888, 0.9881, 0.9883, 0.9865, 0.9844, 0.9889, 0.9881, 0.9872, 0.9871, 0.9896, 0.9881, 0.9898, 0.9889]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MNISTデータセットのロード\n",
    "def load_MNIST(batch=128):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_set = torchvision.datasets.MNIST(root=\"./data\",\n",
    "                                           train=True,\n",
    "                                           download=True,\n",
    "                                           transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                               batch_size=batch,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=2)\n",
    "\n",
    "    val_set = torchvision.datasets.MNIST(root=\"./data\",\n",
    "                                         train=False,\n",
    "                                         download=True,\n",
    "                                         transform=transform)\n",
    "    val_loader =torch.utils.data.DataLoader(val_set,\n",
    "                                            batch_size=batch,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2)\n",
    "\n",
    "    return {\"train\":train_loader, \"validation\":val_loader}\n",
    "\n",
    "#エポック数\n",
    "epoch = 20\n",
    "batch_size = 16 # 64\n",
    "\n",
    "#学習結果の保存\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"validation_loss\": [],\n",
    "    \"validation_acc\": []\n",
    "}\n",
    "\n",
    "#データのロード\n",
    "data_loder = load_MNIST(batch=batch_size)\n",
    "\n",
    "#GPUが使えるときは使う\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#ネットワーク構造の構築\n",
    "net = MyNet().to(device)\n",
    "print(net)\n",
    "\n",
    "#最適化方法の設定\n",
    "optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)\n",
    "\n",
    "for e in range(epoch):\n",
    "    \"\"\" 学習部分 \"\"\"\n",
    "    loss = None\n",
    "    train_loss = 0.0\n",
    "    net.train() #学習モード\n",
    "    print(\"\\nTrain start\")\n",
    "    for i,(data,target) in enumerate(data_loder[\"train\"]):\n",
    "        data,target = data.to(device),target.to(device)\n",
    "\n",
    "        #勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        #順伝搬 -> 逆伝搬 -> 最適化\n",
    "        _, output = net(data)\n",
    "        loss = f.nll_loss(output,target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(\"Training: {} epoch. {} iteration. Loss: {}\".format(e+1,i+1,loss.item()))\n",
    "\n",
    "    train_loss /= len(data_loder[\"train\"])\n",
    "    print(\"Training loss (ave.): {}\".format(train_loss))\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "\n",
    "\n",
    "    \"\"\"検証部分\"\"\"\n",
    "    print(\"\\nValidation start\")\n",
    "    net.eval() #検証モード(Validation)\n",
    "    val_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,target in data_loder[\"validation\"]:\n",
    "            data,target = data.to(device),target.to(device)\n",
    "\n",
    "            #順伝搬の計算\n",
    "            _, output = net(data)\n",
    "            loss = f.nll_loss(output,target).item()\n",
    "            val_loss += f.nll_loss(output,target,reduction='sum').item()\n",
    "            predict = output.argmax(dim=1,keepdim=True)\n",
    "            accuracy += predict.eq(target.view_as(predict)).sum().item()\n",
    "\n",
    "    val_loss /= len(data_loder[\"validation\"].dataset)\n",
    "    accuracy /= len(data_loder[\"validation\"].dataset)\n",
    "\n",
    "    print(\"Validation loss: {}, Accuracy: {}\\n\".format(val_loss,accuracy))\n",
    "\n",
    "    history[\"validation_loss\"].append(val_loss)\n",
    "    history[\"validation_acc\"].append(accuracy)\n",
    "\n",
    "PATH = \"./my_mnist_model.pt\"\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "#結果\n",
    "print(history)\n",
    "plt.figure()\n",
    "plt.plot(range(1, epoch+1), history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(range(1, epoch+1), history[\"validation_loss\"], label=\"validation_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.png\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, epoch+1), history[\"validation_acc\"])\n",
    "plt.title(\"test accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.savefig(\"test_acc.png\")\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f57513",
   "metadata": {},
   "source": [
    "---\n",
    "## 特徴抽出 + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "190d0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Dataset の定義\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root=\"./data\",\n",
    "                                       train=True,\n",
    "                                       download=True,\n",
    "                                       transform=transform)\n",
    "\n",
    "val_set = torchvision.datasets.MNIST(root=\"./data\",\n",
    "                                     train=False,\n",
    "                                     download=True,\n",
    "                                     transform=transform)\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f372ef8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの読み込み\n",
    "model = MyNet()\n",
    "model.load_state_dict(torch.load(\"./my_mnist_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6464ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muto/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# 学習データをモデルに通して，特徴量を取り出す\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size=16, #len(train_set),\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "model.eval() #検証モード(Validation)\n",
    "\n",
    "import numpy as np\n",
    "features = [] # np.empty([16,10])#(16, 10))\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data,target in train_loader:\n",
    "        # print(\"AAA\")\n",
    "        # data,target = data.to(device),target.to(device)\n",
    "\n",
    "        #順伝搬の計算\n",
    "        embed, _ = model(data)\n",
    "        # print(embed.shape)\n",
    "        \n",
    "        features.append(embed.detach().numpy())\n",
    "        targets.append(target.detach().numpy())\n",
    "        \n",
    "X_train = np.array(features).reshape((-1,10))\n",
    "y_train = np.array(targets).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ce14f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ac38a",
   "metadata": {},
   "source": [
    "### SVC のパラメータ最適化\n",
    "(メモ) SVC の gamma を 'auto' に設定すると，随分と時間を要する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36e27d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END .................................C=0.5, gamma=scale; total time=   2.3s\n",
      "[CV] END .................................C=0.5, gamma=scale; total time=   2.4s\n",
      "[CV] END .................................C=0.5, gamma=scale; total time=   2.3s\n",
      "[CV] END .................................C=0.5, gamma=scale; total time=   2.3s\n",
      "[CV] END .................................C=0.5, gamma=scale; total time=   2.3s\n",
      "[CV] END ..................................C=0.5, gamma=auto; total time= 3.1min\n",
      "[CV] END ..................................C=0.5, gamma=auto; total time= 3.2min\n",
      "[CV] END ..................................C=0.5, gamma=auto; total time= 3.2min\n",
      "[CV] END ..................................C=0.5, gamma=auto; total time= 3.1min\n",
      "[CV] END ..................................C=0.5, gamma=auto; total time= 3.1min\n",
      "[CV] END .................................C=1.0, gamma=scale; total time=   1.8s\n",
      "[CV] END .................................C=1.0, gamma=scale; total time=   1.8s\n",
      "[CV] END .................................C=1.0, gamma=scale; total time=   1.8s\n",
      "[CV] END .................................C=1.0, gamma=scale; total time=   1.7s\n",
      "[CV] END .................................C=1.0, gamma=scale; total time=   1.8s\n",
      "[CV] END ..................................C=1.0, gamma=auto; total time= 5.8min\n",
      "[CV] END ..................................C=1.0, gamma=auto; total time= 5.9min\n",
      "[CV] END ..................................C=1.0, gamma=auto; total time= 5.8min\n",
      "[CV] END ..................................C=1.0, gamma=auto; total time= 5.8min\n",
      "[CV] END ..................................C=1.0, gamma=auto; total time= 5.7min\n",
      "[CV] END .................................C=1.5, gamma=scale; total time=   1.5s\n",
      "[CV] END .................................C=1.5, gamma=scale; total time=   1.5s\n",
      "[CV] END .................................C=1.5, gamma=scale; total time=   1.6s\n",
      "[CV] END .................................C=1.5, gamma=scale; total time=   1.5s\n",
      "[CV] END .................................C=1.5, gamma=scale; total time=   1.6s\n",
      "[CV] END ..................................C=1.5, gamma=auto; total time= 6.0min\n",
      "[CV] END ..................................C=1.5, gamma=auto; total time= 6.1min\n",
      "[CV] END ..................................C=1.5, gamma=auto; total time= 6.2min\n",
      "[CV] END ..................................C=1.5, gamma=auto; total time= 6.1min\n",
      "[CV] END ..................................C=1.5, gamma=auto; total time= 6.4min\n",
      "Best params: {'C': 0.5, 'gamma': 'scale'}\n",
      "Best Score: 0.99895\n"
     ]
    }
   ],
   "source": [
    "# SVC のパラメータ最適化\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "parameters = {\n",
    "    \"C\": [0.5, 1.0, 1.5],\n",
    "    \"gamma\" : ('scale', 'auto')\n",
    "}\n",
    "\n",
    "# ハイパーパラメータチューニング(グリッドサーチのコンストラクタにモデルと辞書パラメータを指定)\n",
    "gridsearch = GridSearchCV(estimator=clf,        # モデル\n",
    "                          param_grid=parameters,  # チューニングするハイパーパラメータ\n",
    "                          scoring=\"accuracy\",      # スコアリング\n",
    "                          cv=5,\n",
    "                          verbose=2\n",
    "                         )\n",
    "\n",
    "# Grid Search の実行\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Grid Search の結果から得られた最適なパラメータ候補を出力\n",
    "print('Best params: {}'.format(gridsearch.best_params_)) \n",
    "print('Best Score: {}'.format(gridsearch.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66137d",
   "metadata": {},
   "source": [
    "### 最適化されたパラメータに基づく SVC の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "166e48f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = SVC(kernel='rbf', C=0.5, gamma='scale')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df892a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muto/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9913"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テスト\n",
    "val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                           batch_size=len(val_set),\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "model.eval() #検証モード(Validation)\n",
    "\n",
    "import numpy as np\n",
    "features = [] # np.empty([16,10])#(16, 10))\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data,target in val_loader:\n",
    "        \n",
    "        # print(\"AAA\")\n",
    "        # data,target = data.to(device),target.to(device)\n",
    "\n",
    "        #順伝搬の計算\n",
    "        embed, _ = model(data)\n",
    "        # print(embed.shape)\n",
    "        \n",
    "        features.append(embed.detach().numpy())\n",
    "        targets.append(target.detach().numpy())\n",
    "        \n",
    "X_test = np.array(features).reshape((-1,10))\n",
    "y_test = np.array(targets).reshape(-1)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afb3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
